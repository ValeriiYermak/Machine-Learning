{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Download data for analise\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% some information about data\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% some more information about data\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean from the anomalies\n",
    "columns_to_check = [\"AveRooms\", \"AveBedrms\", \"AveOccup\", \"Population\"]\n",
    "\n",
    "# %% calculate z-scores\n",
    "z_scores = df_cleaned[columns_to_check].apply(zscore)\n",
    "\n",
    "# %% Identify anomalies: where z_score >3 or <-3\n",
    "outliers_mask = (np.abs(z_scores) > 3).any(axis=1)\n",
    "\n",
    "# %% remote lines from the anomalies\n",
    "df_cleaned = df_cleaned[~outliers_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_cleaned.corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation matrix of cleaned data\")\n",
    "plt.show\n",
    "\n",
    "# %% We scale the signs\n",
    "X_features = df_cleaned.drop(columns=[\"MedHouseVal\"])\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_features)\n",
    "\n",
    "# %% Count VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_features.columns\n",
    "vif_data[\"VIF\"] = [\n",
    "    variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])\n",
    "]\n",
    "print(f\"VIF:{vif_data}\")\n",
    "\n",
    "# %% Recalculate VIF without 'Longitude'\n",
    "X_features_reduced = df_cleaned.drop(columns=[\"MedHouseVal\", \"Longitude\"])\n",
    "X_scaled_reduced = scaler.fit_transform(X_features_reduced)\n",
    "\n",
    "vif_data_reduced = pd.DataFrame()\n",
    "vif_data_reduced[\"feature\"] = X_features_reduced.columns\n",
    "vif_data_reduced[\"VIF\"] = [\n",
    "    variance_inflation_factor(X_scaled_reduced, i)\n",
    "    for i in range(X_scaled_reduced.shape[1])\n",
    "]\n",
    "print(\"\\nVIF after removing 'Longitude':\")\n",
    "print(vif_data_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cleaned.drop(columns=[\"MedHouseVal\"])\n",
    "y = df_cleaned[\"MedHouseVal\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# %%\n",
    "# build the model of linear regression\n",
    "\n",
    "model_lin = LinearRegression()\n",
    "model_lin.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred_lin = model_lin.predict(X_test_scaled)\n",
    "\n",
    "# %% evaluation of the model\n",
    "r_sq_upd_lin = model_lin.score(X_train_scaled, y_train)\n",
    "mae_upd_lin = mean_absolute_error(y_test, y_pred_lin)\n",
    "mape_upd_lin = mean_absolute_percentage_error(y_test, y_pred_lin)\n",
    "print()\n",
    "print(\"Linear Regression\")\n",
    "print(f\"R²: {r_sq_upd_lin:.4f} | MAE: {mae_upd_lin:.4f} | MAPE: {mape_upd_lin:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "model_poly = LinearRegression()\n",
    "model_poly.fit(X_train_poly, y_train)\n",
    "\n",
    "y_pred_poly = model_poly.predict(X_test_poly)\n",
    "\n",
    "r2_poly = model_poly.score(X_train_poly, y_train)\n",
    "mae_poly = mean_absolute_error(y_test, y_pred_poly)\n",
    "mape_poly = mean_absolute_percentage_error(y_test, y_pred_poly)\n",
    "print()\n",
    "print(\"Polynomial Regression (level 2):\")\n",
    "print(f\"R2: {r2_poly:.2f} | MAE: {mae_poly:.2f} | MAPE: {mape_poly:.2f}\")\n",
    "\n",
    "# %% Plot of actual vs predicted values for each model\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Linear Regression\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred_lin, alpha=0.5, label=\"Prediction vs Real\")\n",
    "plt.plot(\n",
    "    [y_test.min(), y_test.max()],\n",
    "    [y_test.min(), y_test.max()],\n",
    "    \"r--\",\n",
    "    lw=2,\n",
    "    label=\"Perfect Prediction\",\n",
    ")\n",
    "plt.title(\"Linear Regression: Real vs Predicted\")\n",
    "plt.xlabel(\"Real Features\")\n",
    "plt.ylabel(\"Predicted Features\")\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred_poly, alpha=0.5, label=\"Prediction vs Real\")\n",
    "plt.plot(\n",
    "    [y_test.min(), y_test.max()],\n",
    "    [y_test.min(), y_test.max()],\n",
    "    \"r--\",\n",
    "    lw=2,\n",
    "    label=\"Perfect Prediction\",\n",
    ")\n",
    "plt.title(\"Polynomial Regression: Real vs Predicted\")\n",
    "plt.xlabel(\"Real Features\")\n",
    "plt.ylabel(\"Predicted Features\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Linear Regression\n",
    "plt.subplot(1, 2, 1)\n",
    "residuals_lin = y_test - y_pred_lin\n",
    "sns.scatterplot(x=y_pred_lin, y=residuals_lin, alpha=0.5, label=\"Rating – Real\")\n",
    "plt.hlines(\n",
    "    0,\n",
    "    xmin=y_pred_lin.min(),\n",
    "    xmax=y_pred_lin.max(),\n",
    "    colors=\"r\",\n",
    "    linestyles=\"--\",\n",
    "    label=\"Zero error\",\n",
    ")\n",
    "plt.title(\"Linear Regression: Residual errors\")\n",
    "plt.xlabel(\"Predicted Features\")\n",
    "plt.ylabel(\"Residual errors\")\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals_poly = y_test - y_pred_poly\n",
    "sns.scatterplot(x=y_pred_poly, y=residuals_poly, alpha=0.5, label=\"Rating – Real\")\n",
    "plt.hlines(\n",
    "    0,\n",
    "    xmin=y_pred_poly.min(),\n",
    "    xmax=y_pred_poly.max(),\n",
    "    colors=\"r\",\n",
    "    linestyles=\"--\",\n",
    "    label=\"Zero error\",\n",
    ")\n",
    "plt.title(\"Polynomial Regression: Residual errors\")\n",
    "plt.xlabel(\"Predicted Features\")\n",
    "plt.ylabel(\"Residual errors\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison plot of R2, MAE, MAPE for both models\n",
    "metrics = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\"Linear Regression\", \"Polynomial Regression\"],\n",
    "        \"R2\": [r_sq_upd_lin, r2_poly],\n",
    "        \"MAE\": [mae_upd_lin, mae_poly],\n",
    "        \"MAPE\": [mape_upd_lin, mape_poly],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Prepare of plot\n",
    "metrics.set_index(\"Model\", inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# R2\n",
    "metrics[\"R2\"].plot(kind=\"bar\", ax=ax[0], color=[\"blue\", \"green\"])\n",
    "ax[0].set_title(\"R2: Comparison of models\")\n",
    "ax[0].set_ylabel(\"R2\")\n",
    "\n",
    "# MAE\n",
    "metrics[\"MAE\"].plot(kind=\"bar\", ax=ax[1], color=[\"blue\", \"green\"])\n",
    "ax[1].set_title(\"MAE: Comparison of models\")\n",
    "ax[1].set_ylabel(\"MAE\")\n",
    "\n",
    "# MAPE\n",
    "metrics[\"MAPE\"].plot(kind=\"bar\", ax=ax[2], color=[\"blue\", \"green\"])\n",
    "ax[2].set_title(\"MAPE: Comparison of models\")\n",
    "ax[2].set_ylabel(\"MAPE\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific Conclusions Based on My Results\n",
    "1. Model Performance Comparison\n",
    "In my case, the Polynomial Regression model achieved an R² of 0.70 compared to 0.65 for the Linear Regression model, indicating that the polynomial model better captures the more complex relationships in the data.\n",
    "\n",
    "The MAE and MAPE values for the polynomial model were also lower, showing more accurate average predictions.\n",
    "\n",
    "However, the improvement in metrics is moderate, suggesting that while the polynomial model fits better, the gain is not dramatic.\n",
    "\n",
    "2. Residual Plot Analysis\n",
    "For Linear Regression, the residual plot shows a slight curve pattern, indicating underfitting — the model is not fully capturing the nonlinear trends present in the data.\n",
    "\n",
    "For Polynomial Regression, residuals appear more randomly scattered around zero, which suggests a better fit and more model flexibility.\n",
    "\n",
    "3. Actual vs. Predicted Values Plot\n",
    "The points for the Polynomial Regression are closer to the ideal diagonal line than those of the Linear Regression, confirming the polynomial model’s higher prediction accuracy.\n",
    "\n",
    "Despite this, some scatter remains, indicating residual errors and room for further model improvement.\n",
    "\n",
    "4. Impact of Preprocessing\n",
    "Outlier removal and feature scaling clearly improved the model’s performance, as reflected in better metrics and more stable predictions.\n",
    "\n",
    "Removing highly correlated features (specifically Longitude) significantly reduced multicollinearity (VIF dropped from around 9 to approximately 1), which enhanced the model’s robustness and interpretability.\n",
    "\n",
    "5. Overfitting Considerations\n",
    "Since the polynomial model fits the training data better but only shows modest improvement on the test data, there is a risk of overfitting.\n",
    "\n",
    "To address this, applying regularization techniques such as Ridge or Lasso regression, or lowering the polynomial degree, could be beneficial."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
